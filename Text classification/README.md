<h1>Идентификация тональности текста в описании карточек товара интернет-магазина.<span class="tocSkip"></span></h1>
<h1>Содержание<span class="tocSkip"></span></h1>
<div class="toc"><ul class="toc-item"><li><span><a href="#Подготовка" data-toc-modified-id="Подготовка-1"><span class="toc-item-num">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href="#Обучение" data-toc-modified-id="Обучение-2"><span class="toc-item-num">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href="#Выводы" data-toc-modified-id="Выводы-3"><span class="toc-item-num">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href="#Чек-лист-проверки" data-toc-modified-id="Чек-лист-проверки-4"><span class="toc-item-num">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>

## Описание
Пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. 

Обучаем модель классифицировать комментарии на позитивные и негативные на наборе данных с разметкой о токсичности правок.

Критерий точности модели - метрика качества *F1*, целевой уровень - не меньше 0.75. 

**Ход решения:**

1. Загрузка и подготовка данных.
2. Обучение моделей. 
3. Выводы.

**Описание данных**

Данные находятся в файле `toxic_comments.csv`. Столбец *text* содержит текст комментария, столбец *toxic* — целевой признак.
## Выводы
В ходе работы над проектом было сделано:

- Подготовленны данные обучения на моделях
- Обучены модели и выбраны лучшие на кросс-валидации

На тестовой выбоке по метрике F1 лучше всего себя показал LogisticRegression - 0.766.
CatBoost испытать в полной мере не удалось, из-за отказа ядра. Показель F1 значительно ниже, т.к. для теста был урезан датасет.

Наиболее рационалным решением будет использование лоигистической регресси.

